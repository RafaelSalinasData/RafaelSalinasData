{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8nkMQylMJ9D",
        "outputId": "ece8aa75-c1ee-496c-f9fa-e63690415e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.28\" 2025-07-15\n",
            "OpenJDK Runtime Environment (build 11.0.28+6-post-Ubuntu-1ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.28+6-post-Ubuntu-1ubuntu122.04.1, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "!java -version\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy==2.0.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbZTOAQsMYd_",
        "outputId": "5296fef2-1609-4777-c908-fba50b9e8a34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.5.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q3bRK2xMmUn",
        "outputId": "6797f45d-c6c4-4698-949c-4ebfe6aff854"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==3.5.1 in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark==3.5.1) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6yQ1FE3NKhm",
        "outputId": "b958a7eb-f7dd-4334-b983-b916e38d66ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (15.0.2)\n",
            "Requirement already satisfied: numpy<2,>=1.16.6 in /usr/local/lib/python3.12/dist-packages (from pyarrow) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Crear SparkSession local\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"HousingAdvanced\")\n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "sc = spark.sparkContext\n",
        "\n",
        "print(\"✔ Conectado a Spark\")\n",
        "print(\"Spark version:\", spark.version)\n",
        "print(\"Master:\", sc.master)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJQMUWxPNSbZ",
        "outputId": "96291b67-0f25-4b5b-f87d-833ea9732fc1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Conectado a Spark\n",
            "Spark version: 3.5.1\n",
            "Master: local[*]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/Housing.csv\"\n"
      ],
      "metadata": {
        "id": "0qOL1dtJN7UD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = (\n",
        "    spark.read\n",
        "    .option(\"header\", True)\n",
        "    .option(\"inferSchema\", True)\n",
        "    .csv(csv_path)\n",
        ")\n",
        "\n",
        "print(\"Filas:\", df.count(), \"| Columnas:\", len(df.columns))\n",
        "df.printSchema()\n",
        "\n",
        "# Vista temporal para SQL\n",
        "df.createOrReplaceTempView(\"Housing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJRo6MDpN9ve",
        "outputId": "77bbbcc8-d780-4efc-ac4e-4ef570615789"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filas: 545 | Columnas: 15\n",
            "root\n",
            " |-- price: integer (nullable = true)\n",
            " |-- area: integer (nullable = true)\n",
            " |-- bedrooms: integer (nullable = true)\n",
            " |-- bathrooms: integer (nullable = true)\n",
            " |-- stories: integer (nullable = true)\n",
            " |-- mainroad: string (nullable = true)\n",
            " |-- guestroom: string (nullable = true)\n",
            " |-- basement: string (nullable = true)\n",
            " |-- hotwaterheating: string (nullable = true)\n",
            " |-- airconditioning: string (nullable = true)\n",
            " |-- parking: integer (nullable = true)\n",
            " |-- prefarea: string (nullable = true)\n",
            " |-- furnishingstatus: string (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- zipcode: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estadísticas globales\n",
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "  COUNT(*) AS total_rows,\n",
        "  AVG(price) AS avg_price,\n",
        "  AVG(area) AS avg_area,\n",
        "  AVG(bedrooms) AS avg_bedrooms,\n",
        "  AVG(bathrooms) AS avg_bathrooms\n",
        "FROM housing\n",
        "\"\"\").show()\n",
        "\n",
        "# Promedio de precio por estado de amueblado\n",
        "spark.sql(\"\"\"\n",
        "SELECT furnishingstatus, COUNT(*) AS n, ROUND(AVG(price), 2) AS avg_price\n",
        "FROM housing\n",
        "GROUP BY furnishingstatus\n",
        "ORDER BY avg_price DESC\n",
        "\"\"\").show()\n",
        "\n",
        "# Top 5 zipcodes por precio promedio (mínimo 5 registros)\n",
        "spark.sql(\"\"\"\n",
        "SELECT zipcode, COUNT(*) AS n, ROUND(AVG(price), 2) AS avg_price\n",
        "FROM housing\n",
        "GROUP BY zipcode\n",
        "HAVING COUNT(*) >= 5\n",
        "ORDER BY avg_price DESC\n",
        "LIMIT 5\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9srBGDdNOOa-",
        "outputId": "6056bcb6-b091-4b4e-8806-b16db168bc78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+----------------+------------------+------------------+\n",
            "|total_rows|        avg_price|        avg_area|      avg_bedrooms|     avg_bathrooms|\n",
            "+----------+-----------------+----------------+------------------+------------------+\n",
            "|       545|4766729.247706422|5150.54128440367|2.9651376146788992|1.2862385321100918|\n",
            "+----------+-----------------+----------------+------------------+------------------+\n",
            "\n",
            "+----------------+---+----------+\n",
            "|furnishingstatus|  n| avg_price|\n",
            "+----------------+---+----------+\n",
            "|       furnished|140| 5495696.0|\n",
            "|  semi-furnished|227|4907524.23|\n",
            "|     unfurnished|178|4013831.46|\n",
            "+----------------+---+----------+\n",
            "\n",
            "+-------+---+----------+\n",
            "|zipcode|  n| avg_price|\n",
            "+-------+---+----------+\n",
            "|  33213|182|4782444.23|\n",
            "|  33214|182|4759921.15|\n",
            "|  33215|181|4757773.15|\n",
            "+-------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "print(\"Particiones actuales:\", df.rdd.getNumPartitions())\n",
        "\n",
        "# Reparticionar por zipcode\n",
        "df_zip = df.repartition(8, \"zipcode\")\n",
        "print(\"Particiones después de repartition:\", df_zip.rdd.getNumPartitions())\n",
        "\n",
        "# Coalesce a 2 particiones\n",
        "df_zip2 = df_zip.coalesce(2)\n",
        "print(\"Particiones después de coalesce:\", df_zip2.rdd.getNumPartitions())\n",
        "\n",
        "# Escritura en Parquet con partición\n",
        "parquet_path = \"/content/output/parquet_partitioned\"\n",
        "(\n",
        "    df.write\n",
        "    .mode(\"overwrite\")\n",
        "    .partitionBy(\"year\", \"furnishingstatus\")\n",
        "    .parquet(parquet_path)\n",
        ")\n",
        "\n",
        "print(\"✔ Parquet escrito en:\", parquet_path)\n",
        "\n",
        "# Leer el Parquet\n",
        "df_parq = spark.read.parquet(parquet_path)\n",
        "df_parq.groupBy(\"year\", \"furnishingstatus\").count().orderBy(\"year\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oSGNPS2OdDx",
        "outputId": "6cd875fe-ef49-4a3a-a3a1-ce9a1eddaf5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Particiones actuales: 1\n",
            "Particiones después de repartition: 8\n",
            "Particiones después de coalesce: 2\n",
            "✔ Parquet escrito en: /content/output/parquet_partitioned\n",
            "+----+----------------+-----+\n",
            "|year|furnishingstatus|count|\n",
            "+----+----------------+-----+\n",
            "|2015|  semi-furnished|   85|\n",
            "|2015|     unfurnished|   56|\n",
            "|2015|       furnished|   41|\n",
            "|2016|  semi-furnished|   73|\n",
            "|2016|       furnished|   54|\n",
            "|2016|     unfurnished|   55|\n",
            "|2017|     unfurnished|   67|\n",
            "|2017|  semi-furnished|   69|\n",
            "|2017|       furnished|   45|\n",
            "+----+----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow.csv as pa_csv\n",
        "import pyarrow.parquet as pq\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "e9iEVbAKP45b"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_csv = pa_csv.read_csv(\"/content/Housing.csv\")\n",
        "print(\"Datos cargados con PyArrow desde CSV:\")\n",
        "print(table_csv.schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxR-1OdyP_Tv",
        "outputId": "095368d1-a75f-4d72-fbca-7a99f845e042"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos cargados con PyArrow desde CSV:\n",
            "price: int64\n",
            "area: int64\n",
            "bedrooms: int64\n",
            "bathrooms: int64\n",
            "stories: int64\n",
            "mainroad: string\n",
            "guestroom: string\n",
            "basement: string\n",
            "hotwaterheating: string\n",
            "airconditioning: string\n",
            "parking: int64\n",
            "prefarea: string\n",
            "furnishingstatus: string\n",
            "year: int64\n",
            "zipcode: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pq.write_table(table_csv, \"/content/Housing.parquet\")\n"
      ],
      "metadata": {
        "id": "-fi4l5_mQEgh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_parquet = pq.read_table(\"/content/Housing.parquet\")\n",
        "print(\"\\nDatos cargados desde Parquet:\")\n",
        "print(table_parquet.schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBMM_8StQJUw",
        "outputId": "0c5d3508-be0f-49c1-aa09-e837f05f7269"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Datos cargados desde Parquet:\n",
            "price: int64\n",
            "area: int64\n",
            "bedrooms: int64\n",
            "bathrooms: int64\n",
            "stories: int64\n",
            "mainroad: string\n",
            "guestroom: string\n",
            "basement: string\n",
            "hotwaterheating: string\n",
            "airconditioning: string\n",
            "parking: int64\n",
            "prefarea: string\n",
            "furnishingstatus: string\n",
            "year: int64\n",
            "zipcode: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir a DataFrame de Pandas\n",
        "df_pandas = table_parquet.to_pandas()\n",
        "print(\"\\nPrimeras filas del DataFrame Pandas:\")\n",
        "print(df_pandas.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrhicoZ2QShd",
        "outputId": "adc0fabc-1725-484d-ab6b-434fdf233015"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Primeras filas del DataFrame Pandas:\n",
            "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
            "0  13300000  7420         4          2        3      yes        no       no   \n",
            "1  12250000  8960         4          4        4      yes        no       no   \n",
            "2  12250000  9960         3          2        2      yes        no      yes   \n",
            "3  12215000  7500         4          2        2      yes        no      yes   \n",
            "4  11410000  7420         4          1        2      yes       yes      yes   \n",
            "\n",
            "  hotwaterheating airconditioning  parking prefarea furnishingstatus  year  \\\n",
            "0              no             yes        2      yes        furnished  2015   \n",
            "1              no             yes        3       no        furnished  2016   \n",
            "2              no              no        2      yes   semi-furnished  2017   \n",
            "3              no             yes        3      yes        furnished  2015   \n",
            "4              no             yes        2       no        furnished  2016   \n",
            "\n",
            "   zipcode  \n",
            "0    33213  \n",
            "1    33214  \n",
            "2    33215  \n",
            "3    33213  \n",
            "4    33214  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "df_spark = spark.read.csv(\"/content/Housing.csv\", header=True, inferSchema=True)\n",
        "print(\"Primeras filas del DataFrame en Spark:\")\n",
        "df_spark.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUjATMO0RM_X",
        "outputId": "6dd56888-9148-48bb-8cfa-0315af7d09ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeras filas del DataFrame en Spark:\n",
            "+--------+----+--------+---------+-------+--------+---------+--------+---------------+---------------+-------+--------+----------------+----+-------+\n",
            "|   price|area|bedrooms|bathrooms|stories|mainroad|guestroom|basement|hotwaterheating|airconditioning|parking|prefarea|furnishingstatus|year|zipcode|\n",
            "+--------+----+--------+---------+-------+--------+---------+--------+---------------+---------------+-------+--------+----------------+----+-------+\n",
            "|13300000|7420|       4|        2|      3|     yes|       no|      no|             no|            yes|      2|     yes|       furnished|2015|  33213|\n",
            "|12250000|8960|       4|        4|      4|     yes|       no|      no|             no|            yes|      3|      no|       furnished|2016|  33214|\n",
            "|12250000|9960|       3|        2|      2|     yes|       no|     yes|             no|             no|      2|     yes|  semi-furnished|2017|  33215|\n",
            "|12215000|7500|       4|        2|      2|     yes|       no|     yes|             no|            yes|      3|     yes|       furnished|2015|  33213|\n",
            "|11410000|7420|       4|        1|      2|     yes|      yes|     yes|             no|            yes|      2|      no|       furnished|2016|  33214|\n",
            "+--------+----+--------+---------+-------+--------+---------+--------+---------------+---------------+-------+--------+----------------+----+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columnas disponibles en el DataFrame:\")\n",
        "print(df_spark.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whft0NWASoZr",
        "outputId": "654bab31-f33f-4add-b285-e230294c5238"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas disponibles en el DataFrame:\n",
            "['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus', 'year', 'zipcode']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear vista temporal\n",
        "df_spark.createOrReplaceTempView(\"housing\")\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT AVG(`area`) AS promedio_lotarea\n",
        "FROM housing\n",
        "\"\"\"\n",
        "df_sql = spark.sql(query)\n",
        "df_sql.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6MvgSI0Ta3L",
        "outputId": "4ea7d743-3233-4b53-8f25-4ef64a3b09e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|promedio_lotarea|\n",
            "+----------------+\n",
            "|5150.54128440367|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Repartition y Coalesce\n",
        "print(\"\\nNúmero de particiones originales:\", df_spark.rdd.getNumPartitions())\n",
        "\n",
        "# Reparticionar a 4 particiones\n",
        "df_repart = df_spark.repartition(4)\n",
        "print(\"Número de particiones tras Repartition:\", df_repart.rdd.getNumPartitions())\n",
        "\n",
        "# Reducir particiones con Coalesce\n",
        "df_coalesce = df_repart.coalesce(2)\n",
        "print(\"Número de particiones tras Coalesce:\", df_coalesce.rdd.getNumPartitions())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWsUrxE0Tu8X",
        "outputId": "0ca97c72-edd8-4b6e-afe9-164bcd629a54"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Número de particiones originales: 1\n",
            "Número de particiones tras Repartition: 4\n",
            "Número de particiones tras Coalesce: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Exportar resultados en formato Parquet\n",
        "output_path = \"/content/housing_parquet\"\n",
        "df_coalesce.write.mode(\"overwrite\").parquet(output_path)\n",
        "print(\"\\nArchivo guardado en formato Parquet en:\", output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txT5LijwT3Ha",
        "outputId": "e6751f6d-7643-4943-f3ea-0def66e8b996"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Archivo guardado en formato Parquet en: /content/housing_parquet\n"
          ]
        }
      ]
    }
  ]
}